    #!/usr/bin/env python3
#
#  Purpose: This service listens for new events submitted to Sealog, create
#           aux_data records containing the specified real-time data and
#           associates the aux data records with the newly created event.
#
#           This script leverages the OpenRVDAS/InfluxDB integration so that
#           if can add ancillary data from any point in time so long as the
#           data is availble from the InfluxDB.  In the event the data is not 
#           available the script will NOT add the corresponding aux_data
#           records.
#
#    Usage: Type python3 sealog-auxDataInserter-influx.py to start the service.
#
#           This serivce runs in the forground. Type ^d to kill the service.
#
#   Author: Webb Pinner webbpinner@gmail.com
#  Created: 2021-04-01
# Modified: 

import sys
import asyncio
import websockets
import time
import json
import yaml
import requests
import logging
from datetime import datetime, timedelta
from influxdb_client import InfluxDBClient

from python_sealog.settings import apiServerURL, wsServerURL, eventAuxDataAPIPath, headers
from influx_sealog.settings import influxServerURL, influxToken, influxOrg
from influx_sealog.aux_data_record_builder import SealogInfluxAuxDataRecordBuilder

#-----------------------------------------------------------------------------#

inline_config = '''
-
    data_source: realtimeVesselPosition
    query_measurements:
        - seapath1
    aux_record_lookup:
        S1HeadingTrue:
            name: heading
            uom: deg
            round: 3
        S1Latitude:
            name: latitude
            uom: ddeg
            round: 6
            modify:
                -
                    test:
                        -
                            field: S1NorS
                            eq: "S"
                    operation:
                        -
                            multiply: -1
        S1Longitude:
            name: longitude
            uom: deg
            round: 6
            modify:
                -
                    test:
                        -
                            field: S1EorW
                            eq: "W"
                    operation:
                        -
                            multiply: -1
        S1NorS:
            no_output: true
        S1EorW:
            no_output: true
'''

# set of events to ignore
EXCLUDE_SET = ()

# needs to be unique for all currently active dataInserter scripts.
clientWSID = 'auxData-dataInserter-influx'

hello = {
    'type': 'hello',
    'id': clientWSID,
    'auth': {
        'headers': headers
    },
    'version': '2',
    'subs': ['/ws/status/newEvents']
}

ping = {
    'type':'ping',
    'id':clientWSID
}

# default log level
LOG_LEVEL = logging.INFO

# create logger
logging.basicConfig(level=LOG_LEVEL,
                    format='%(asctime)s - %(name)s:%(lineno)s - %(levelname)s - %(message)s'
                   )

logger = logging.getLogger(__file__)

async def auxDataInserter(aux_data_builders):

    try:
        async with websockets.connect(wsServerURL) as websocket:

            await websocket.send(json.dumps(hello))

            while(True):

                event = await websocket.recv()
                eventObj = json.loads(event)

                if eventObj['type'] and eventObj['type'] == 'ping':
                    await websocket.send(json.dumps(ping))
                elif eventObj['type'] and eventObj['type'] == 'pub':

                    if eventObj['message']['event_value'] in EXCLUDE_SET:
                        logger.debug("Skipping because event value is in the exclude set")
                        continue

                    logger.debug("Event: %s" % eventObj['message'])

                    # Build the aux_data records for the given event
                    for builder in aux_data_builders:
                        logger.debug("Building aux data record")
                        record = builder.buildAuxDataRecord(eventObj['message'])
                        if record:
                            try:
                                logger.debug("Submitting aux data record to Sealog Server")
                                logger.debug(json.dumps(record))
                                r = requests.post(apiServerURL + eventAuxDataAPIPath, headers=headers, data = json.dumps(record))
                                logger.debug("Response: " + r.text)

                            except Exception as error:
                                logger.warning("Error submitting aux data record")
                                logger.debug(str(error))
                        else:
                            logger.debug("No aux data for data_source: %s" % builder.data_source)

    except Exception as error:
        logger.error(str(error))
        raise error

if __name__ == '__main__':

    import argparse
    import os
    import sys

    parser = argparse.ArgumentParser(description='Aux Data Inserter Service - InfluxDB')
    parser.add_argument('-d', '--debug', action='store_true', help=' display debug messages')
    parser.add_argument('-f', '--config_file', help=' used the specifed configuration file')

    args = parser.parse_args()

    # Turn on debug mode
    if args.debug:
        logger.info("Setting log level to DEBUG")
        logger.setLevel(logging.DEBUG)
        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)
        logger.debug("Log level now set to DEBUG")

    aux_data_configs = None
  
    if args.config_file:
        try:
            with open(args.config_file) as file:
                aux_data_configs = yaml.safe_load(file)
        except yaml.parser.ParserError:
            logging.error("Invalid YAML syntax")
            sys.exit(1)
    else:
        try:
            aux_data_configs = yaml.safe_load(inline_config)
        except yaml.parser.ParserError:
            logging.error("Invalid YAML syntax")
            sys.exit(1)

    logger.debug(json.dumps(aux_data_configs, indent=2))

    # create an influxDB Client
    client = InfluxDBClient(url=influxServerURL, token=influxToken, org=influxOrg)

    # Create the Aux Data Record Builders
    aux_data_builders = list(map(lambda config: SealogInfluxAuxDataRecordBuilder(client, config), aux_data_configs))

    # Run the main loop
    while True:

        # Wait 5 seconds for the server to complete startup
        time.sleep(5)

        try:
            logger.debug("Connecting to event websocket feed...")
            asyncio.get_event_loop().run_until_complete(auxDataInserter(aux_data_builders))
        except KeyboardInterrupt:
            logger.error('Keyboard Interrupted')
            try:
                sys.exit(0)
            except SystemExit:
                os._exit(0)
        except Exception as error:
            logger.debug(str(error))
            logger.error("Lost connection to server, trying again in 5 seconds")
