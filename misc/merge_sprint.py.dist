#!/usr/bin/env python3
#
#  Purpose: This script takes a lowering ID and renav raw sprint file and 
#           creates new aux_data records within Sealog
#
#    Usage: Type python3 merge_sprint.py <lowering_id> <raw_sprint_file> to run the script.
#            - <lowering_id>: the lowering ID (J2-1042)
#            - <raw_sprint_file>: the raw_sprint file name with absolute/relative path (./UDP-SB-SPRINT-RAW_20200128-234312.Raw)
#
#   Author: Webb Pinner webbpinner@gmail.com
#  Created: 2018-11-07
# Modified: 2020-02-21

import requests
import json
import csv
import logging
from datetime import datetime

from python_sealog.settings import apiServerURL, eventAuxDataAPIPath, headers
from python_sealog.lowerings import getLoweringUIDByID
from python_sealog.events import getEventsByLowering

# default log level
LOG_LEVEL = logging.INFO

# create logger
logging.basicConfig(level=LOG_LEVEL,
                    format='%(asctime)s - %(name)s:%(lineno)s - %(levelname)s - %(message)s'
                   )

logger = logging.getLogger(__file__)

auxDataTemplate = {
    'event_id': None,
    'data_source': None,
    'data_array': []
}

def match_raw_sprint_to_event(raw_sprint_file, events, dryrun):

    # print(json.dumps(events, indent=2))
    for event in events:
        event['ts'] = datetime.strptime(event['ts'], '%Y-%m-%dT%H:%M:%S.%fZ').strftime('%Y-%m-%dT%H:%M:%S.000Z')

    # print(events)

    raw_data_array = []

    with open(raw_sprint_file) as f:
        reader = csv.reader(f, skipinitialspace=True)
        # header = next(reader) # skip header

        for row in reader:

            # print(row)
            
            raw_ts = datetime.strptime(row[0] + ' ' + row[1], '%m/%d/%Y %H:%M:%S.%f').strftime('%Y-%m-%dT%H:%M:%S.000Z')
            eventIDArray = filter(lambda event: event['ts'] == raw_ts, events)

            for event in eventIDArray:
                # print("event:", json.dumps(event))
                try:
                    raw_data = {}
                    raw_data['event_id'] = event['id']
                    raw_data['data_source'] = "vehicleRealtimeNavData"
                    raw_data['data_array'] = []
                    if float(row[7]) != 0:
                        raw_data['data_array'].append({ 'data_name': "latitude",'data_value': float(row[7]), 'data_uom': 'ddeg' })
                    if float(row[8]) != 0:
                        raw_data['data_array'].append({ 'data_name': "longitude",'data_value': float(row[8]), 'data_uom': 'ddeg' })
                    raw_data['data_array'].append({ 'data_name': "depth",'data_value': float(row[15]), 'data_uom': 'm' })
                    raw_data['data_array'].append({ 'data_name': "altitude",'data_value': float(row[13]), 'data_uom': 'm' })
                    raw_data['data_array'].append({ 'data_name': "heading",'data_value': float(row[5]), 'data_uom': 'deg' })
                    raw_data['data_array'].append({ 'data_name': "pitch",'data_value': float(row[4]), 'data_uom': 'deg' })
                    raw_data['data_array'].append({ 'data_name': "roll",'data_value': float(row[3]), 'data_uom': 'deg' })

                    logger.debug("Adding Aux Data Record to event: " + event['ts'] + ' --> ' + event['event_value'])
                except:
                    logger.debug("Unable to process row")
                    logger.debug(row)
                    continue

                if not dryrun:
                    try:

                        r = requests.post(apiServerURL + eventAuxDataAPIPath, headers=headers, data = json.dumps(raw_data))
                    except Exception as error:
                        logger.debug("Error: " + error)
                        logger.debug("Event: " + event)

if __name__ == '__main__':

    import argparse
    import sys
    import os


    parser = argparse.ArgumentParser(description='Sealog Vessel GGA Inserter 2000')
    parser.add_argument('-d', '--debug', action='store_true', help=' display debug messages')
    parser.add_argument('-n', '--dryrun', action='store_true', default=False, help=' build new aux data records but do not commit the records to the database')
    parser.add_argument('lowering_id', help='The lowering to process (i.e. S0314)')
    parser.add_argument('raw_sprint_file', help='The raw_sprint file containing the vehicle postion/attitude data')

    args = parser.parse_args()

    # Turn on debug mode
    if args.debug:
        logger.info("Setting log level to DEBUG")
        logger.setLevel(logging.DEBUG)

        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)

        logger.debug("Log level now set to DEBUG")

    if not os.path.isfile(args.raw_sprint_file):
        logger.debug("ERROR: raw_sprint file " + args.raw_sprint_file + " not found")
        sys.exit(1)

    lowering_uid = getLoweringUIDByID(args.lowering_id)

    if not lowering_uid:
        logger.debug("ERROR: lowering " + args.lowering_id + " not found")
        sys.exit(1)

    logger.debug("lowering_uid: " + lowering_uid)
    lowering_events = getEventsByLowering(lowering_uid)

    match_raw_sprint_to_event(args.raw_sprint_file, lowering_events, args.dryrun)